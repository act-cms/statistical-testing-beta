{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How Heavy is that Penny? (Piloted Spring 2025) (Student Version)\n",
        "\n",
        "## ***Important: File → Save a copy in Drive (Do this first so you can save your work!)***\n",
        "\n",
        "Pennies are manufactured to a given specification, including a specific mass.  Do those specifications change predictably over time?  Does normal wear and tear change the mass predictably over time?  \n",
        "\n",
        "Because of the randomness inherent in both manufacturing and normal wear and tear, statistical testing is required to answer such questions.\n",
        "\n",
        "This exercise will require insight and decision-making. Use your teamwork skills to decide as a group how to interpret and proceed forward at each step of these analysis tasks.\n",
        "\n",
        "**Prior Knowledge Needed**\n",
        "*  Basic statistical definitions including mean and standard deviation\n",
        "\n",
        "**Content Learning Objectives:**\n",
        "*   Define and use statistical concepts that model the effects of random error on a data set\n",
        "*   Use careful documentation and/or the statistical Grubbs Test to decide when a data point can be discarded\n",
        "*   Apply the Student T test to accept or reject a null hypothesis under several different sets of conditions\n",
        "\n",
        "**Process Learning Objectives:**\n",
        "*   Use Python code to transform data using structures such as arrays\n",
        "*   Use Python code to visualize data using different types of graphs\n",
        "*   Work in teams to manage and share data, and document and share causes of outlier data\n",
        "*   Work in teams to evaluate outcomes of statistical tests\n",
        "\n",
        "**Overview:**\n",
        "\n",
        "This Jupyter notebook can be used to generate code in Python to perform a variety of statistical analysis tasks:\n",
        "\n",
        "1.  Upload multiple CSV files using Pandas.\n",
        "2.  Reorganize class data into NumPy arrays; calculate the mean and standard deviation over each NumPy array.\n",
        "4.  Use the statistical Grubbs test to recognize and remove true outliers.  \n",
        "  *Optionally, take additional action to document and correct possible data entry errors*.\n",
        "5.  Apply the statistical Student T test to determine whether two sets of data are significantly different.\n",
        "6.  Perform a linear least-squares analysis with error propagation, and determine whether the slope of the best-fit line is significantly different from zero.\n",
        "7.  Construct a histogram of stored data; construct a Gaussian model distribution; and use a statistical chi-squared test to determine whether the histogram is significantly different from the Gaussian model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kB5v9bXGb32J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Uploading multiple CSV files using Pandas\n",
        "\n",
        "#### **Important**: Record the masses and years of all available pennies first.  Each student's recorded data should be compiled in Microsoft Excel to generate and export a CSV file with masses in the first column and years in the second column, with the word \"Brass\" or \"Zinc\" and the student's initials in the filename.\n",
        "\n",
        "#### **Important**: Upload the CSV files to Colab:\n",
        "* First click the file folder icon to expand the Files sidebar.\n",
        "* Next click the file upload icon to upload ALL CSV files in class data.\n",
        "* Enter the filenames into the code as instructed below.\n",
        "\n",
        "To upload multiple CSV files containing data on different types of pennies, we will use several packages.  The IO package allows us to read files, and the Pandas package allows us to interpret CSV files in the database format using the rows and columns of the CSV file.  This will import the CSV data into a dataframe within this Jupyter notebook.\n",
        "\n",
        "The sample-code here uses several data structures: *arrays*; *dictionaries*; and *dataframes*.  It also uses several coding structures: a *function* that is used more than once to upload and combine the named CSV files into a dataframe; and a *for-loop* (which uses \"for\") to convert each uploaded file one-by-one.\n",
        "\n",
        "1a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "1b) Enter **all** filenames of uploaded CSV files into the sample-code below within square brackets, separated by commas.  Each filename must be enclosed in quotes (like the example shown here):\n",
        "\n",
        "---\n",
        "```python\n",
        "['filename_1','filename_2',...]\n",
        "```\n",
        "---\n",
        "\n",
        "1c) Copy/paste all the code below, with your commented explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "1d) Finally, **answer the key question below** in your laboratory notebook. Discuss as a group. Ask for help if needed.\n",
        "\n",
        "#### **Thinking About the Data, Task 1**: Suppose you thought you uploaded all the data files, but when you run the code below, the output doesn't look right.  *What should you do if*:\n",
        "*   Q1a) Running the code below yields an error message.\n",
        "*   Q1b) Running the code below yields the output \"Importing 0 files:\" and \"Importing 0 files:\"\n",
        "\n",
        "---\n",
        "```python\n",
        "#### This streamlined code REQUIRES students to first upload the files into the file browser, or connect to Google Drive.\n",
        "#### The code below is for:\n",
        "brass_filenames = ['filename1.csv','filename2.csv']\n",
        "zinc_filenames = ['filename3.csv','filename4.csv']\n",
        "\n",
        "#### The code below is for:\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "#### The code below is for:\n",
        "def multiple_csv_dataframe(filenames):\n",
        "    #### The code below is for:\n",
        "    length = len(filenames)\n",
        "    print (f\"Importing {length} files:\")\n",
        "\n",
        "    #### The code below is for:\n",
        "    dictionary = {}\n",
        "    index = 0\n",
        "    #### The code below is for:\n",
        "    for filename in filenames:\n",
        "        #### The code below is for:\n",
        "        print(filename)       \n",
        "        #### The code below is for:\n",
        "        dictionary[index] = pd.read_csv(filename)\n",
        "        index = index + 1\n",
        "\n",
        "    #### The code below is for:\n",
        "    print(f\"Combining {length} dataframes\")\n",
        "    combined_dataframe = pd.concat(dictionary)\n",
        "    return combined_dataframe\n",
        "\n",
        "#### The code below is for:\n",
        "big_db = multiple_csv_dataframe(brass_filenames)\n",
        "big_dz = multiple_csv_dataframe(zinc_filenames)\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "zLMz-UmVhJDX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsTJW0vaaTBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Reorganizing class data into NumPy arrays.\n",
        "\n",
        "#### **Important**: Complete Task 1 first.\n",
        "\n",
        "The sample-code here reorganizes data from the imported dataframes into NumPy arrays, covering all years for which data are available.  A *dictionary* allows each array to be accessed by year.  A *for-loop* ensures all available data are parsed.  \n",
        "\n",
        "2a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "2b) Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "2c) Take a look at the output and **decide as a group** if it looks reasonable.  Ask for help if needed.\n",
        "\n",
        "2d) Finally, **answer the key question below** in your laboratory notebook.  Discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About the Data, Task 2** Here are the focus questions at the top of this document.  How could the output from Task 2 help you to answer these questions?  For each question, *make a prediction* as to what you might see in the output below if the answer is yes, and how that might differ if the answer is no.  Finally, take a look at the output and write down what you notice.\n",
        "*   Q2a) Pennies are manufactured to a given specification, including a specific mass.  Do those specifications change predictably over time?\n",
        "*   Q2b) Does normal wear and tear change the mass predictably over time?\n",
        "*   Q2c) Is there anything you notice right away in the output?\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "import numpy as np\n",
        "\n",
        "#### The code below is for:\n",
        "print(f\"Creating separate arrays for masses of brass pennies in each year...\")\n",
        "y1b = np.min(big_db.iloc[:,1])\n",
        "y2b = np.max(big_db.iloc[:,1])\n",
        "print(f\"...from {y1b} to {y2b}\")\n",
        "#### The code below is for:\n",
        "big_grouped_db = big_db.groupby(by=[\"Year\"])\n",
        "\n",
        "#### The code below is for:\n",
        "brass_mass_by_year = np.empty(0)\n",
        "#### The code below is for:\n",
        "for year, data in big_grouped_db:\n",
        "    y = year[0]\n",
        "    year_array = data[\"Mass (g)\"].values\n",
        "    brass_mass_by_year[y] = year_array\n",
        "    print(f\"For year {y}, {len(year_array)} masses were counted, with average and standard deviation of {np.average(year_array):.4f} ± {np.std(year_array,ddof=1):.4f} g.\")\n",
        "\n",
        "#### The code below is for:\n",
        "print(f\"Creating separate arrays for masses of zinc pennies in each year...\")\n",
        "y1z = np.min(big_dz.iloc[:,1])\n",
        "y2z = np.max(big_dz.iloc[:,1])\n",
        "print(f\"...from {y1z} to {y2z}\")\n",
        "#### The code below is for:\n",
        "big_grouped_dz = big_dz.groupby(by=[\"Year\"])\n",
        "\n",
        "#### The code below is for:\n",
        "zinc_mass_by_year = np.empty(0)\n",
        "#### The code below is for:\n",
        "for year, data in big_grouped_dz:\n",
        "    y = year[0]\n",
        "    year_array = data[\"Mass (g)\"].values\n",
        "    zinc_mass_by_year[y] = year_array\n",
        "    print(f\"For year {y}, {len(year_array)} masses were counted, with average and standard deviation of {np.average(year_array):.4f} ± {np.std(year_array,ddof=1):.4f} g.\")\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "rYY9BOvzqBJk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZzCN4tH5GiIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Use the statistical Grubbs test to recognize outliers.\n",
        "\n",
        "#### **Important**: Complete Task 2 first.\n",
        "\n",
        "The sample-code here uses a Grubbs table to recognize outliers.  The Grubbs test is found in the outliers module in the outlier_utils package.  It will automatically remove any outlier it finds.\n",
        "\n",
        "3a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "3b) Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "3c) Take a look at the output and **decide as a group** if it looks reasonable. Ask for help if needed.\n",
        "\n",
        "3d) Finally,  **answer the key question below** in your laboratory notebook, discuss as a group, and take any steps your group deems appropriate.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data, Task 3**: Suppose when you run the code below, an outlier was found.  Everyone else sees the same result when they run the code, and talks about it.  What should **you** do if running the code below yields an outlier, and:\n",
        "*   Q3a) The student who measured that mass says it was a typo, and offers the correct value?\n",
        "*   Q3b) The student who measured that mass says it was zinc and not brass?\n",
        "*   Q3c) Nobody seems to have measured that mass?\n",
        "\n",
        "***After answering these questions:*** Take any steps your group deems appropriate for the results *you* see in the output below.  \n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "%pip install outlier_utils  --quiet\n",
        "from outliers import smirnov_grubbs as grubbs\n",
        "print(\"Package installed!\")\n",
        "\n",
        "#### The code below is for:\n",
        "brass_avg_by_year = np.empty(0)\n",
        "#### The code below is for:\n",
        "for y, data in big_grouped_db:\n",
        "    year = y[0]\n",
        "    #### The code below is for:  \n",
        "    data1 = brass_mass_by_year[year]\n",
        "    #### The code below is for:  \n",
        "    data2 = grubbs.test(data1, alpha=.05)    \n",
        "    #### The code below is for:\n",
        "    if(len(data2)==len(data1)):\n",
        "        print(f\"Year {year}: All {len(data1)} masses of brass pennies passed Grubbs test\")\n",
        "    #### The code below is for:  \n",
        "    else:\n",
        "        failed = len(data1) - len(data2)\n",
        "        print(f\"Year {year}: {failed} masses of brass pennies failed Grubbs test. Masses rejected: {np.setdiff1d(data1,data2)}\")\n",
        "        brass_mass_by_year[year] = data2\n",
        "    #### The code below is for:\n",
        "    brass_avg_by_year = np.append(brass_avg_by_year,np.average(data2))\n",
        "\n",
        "\n",
        "#### The code below is for:\n",
        "zinc_avg_by_year = np.empty(0)\n",
        "#### The code below is for:\n",
        "for y, data in big_grouped_dz:\n",
        "    year = y[0]\n",
        "    #### The code below is for:  \n",
        "    data1 = zinc_mass_by_year[year]\n",
        "    #### The code below is for:  \n",
        "    data2 = grubbs.test(data1, alpha=.05)    \n",
        "    #### The code below is for:  \n",
        "    if(len(data2)==len(data1)):\n",
        "        print(f\"Year {year}: All {len(data1)} masses of zinc pennies passed Grubbs test\")\n",
        "    #### The code below is for:\n",
        "    else:\n",
        "        failed = len(data1) - len(data2)\n",
        "        print(f\"Year {year}: {failed} masses of zinc pennies failed Grubbs test. Masses rejected: {np.setdiff1d(data1,data2)}\")\n",
        "        zinc_mass_by_year[year] = data2\n",
        "    #### The code below is for:\n",
        "    zinc_avg_by_year = np.append(zinc_avg_by_year,np.average(data2))\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "IPNs6Abm-Ei8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBs5ZQ5YRCxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Apply the statistical Student T test to determine whether two sets of data are significantly different.\n",
        "\n",
        "#### **Important**: Complete Task 3 first.  Look at the output to verify it is reasonable.  Take any actions deemed necessary.\n",
        "\n",
        "The sample-code here uses a Student T test to look for significant differences between masses of pennies with the same composition, manufactured in different years.  First, we will use the saved yearly averages from Task 2 to choose the two years of manufacture that differ the most from one another, for each manufacturing material (brass and zinc).  We must recalculate the mean values and standard deviations for those years, in case outliers were removed in Task 3.\n",
        "\n",
        "The Student T statistic can be calculated (using the Python math module) for two comparable data sets using a pooled standard uncertainty:\n",
        "\n",
        "$t_{calc} = \\frac{|\\bar{x}_1-\\bar{x}_2|}{u_{pooled}}$ where\n",
        "$u_{pooled} = s_{pooled}\\cdot\\sqrt{\\frac{N_1+N_2}{N_1\\cdot N_2}}$ and\n",
        "$s_{pooled} = \\sqrt{\\frac{s_1^2\\cdot (N_1-1)+s_2^2\\cdot (N_2-1)}{N_1+N_2-2}}$.\n",
        "\n",
        "The critical value of the Student T statistic can be found in your textbook for a given confidence level (usually 95%), or looked up using the the SciPy package.  If the calculated Student T statistic is larger than the critical value, then the difference between the two data sets is significant at this level of confidence.\n",
        "\n",
        "The SciPy package also has pre-programmed Student T test functions.  These do not output the critical T value, but they do output the p-value, which is the probability of the null hypothesis.  If the p-value is 0.05 or less, then the difference between the two data sets is significant at the 95% level of confidence.\n",
        "\n",
        "We will run the test two ways: first using sample-code to build a test function that can accept Numpy arrays as input, and then using the pre-programmed test function.  \n",
        "\n",
        "4a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "4b)  Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "4c)  Take a look at the output and **decide as a group** if it looks reasonable. Ask for help if needed.\n",
        "\n",
        "4d)  Finally,  **answer the key question below** in your laboratory notebook.  Discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About The Data, Task 4**: Now that you have run the Student T test, what does it mean?\n",
        "*   Q4a) State the *null hypothesis* in your own words.  Be specific.\n",
        "*   Q4b) State the conclusions you should draw if $t_{calc} < t_{table}$, and if $t_{calc} > t_{table}$.\n",
        "*   Q4c) State the conclusions you should draw if $p < 0.05$, and if $p > 0.05$.\n",
        "*   Q4d) **As a group**, use the output from Task 4 to begin to answer the focus questions, in light of the predictions you made in Task 2 for both the brass pennies and zinc pennies.  \n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "import math\n",
        "import scipy as sp\n",
        "\n",
        "#### The code below is for:\n",
        "def t_calc_pooled(array1,array2):\n",
        "    #### The code below is for:\n",
        "    n1 = len(array1)\n",
        "    n2 = len(array2)\n",
        "    #### The code below is for:\n",
        "    x1 = np.average(array1)\n",
        "    x2 = np.average(array2)\n",
        "    #### The code below is for:\n",
        "    s1 = np.std(array1,ddof=1)\n",
        "    s2 = np.std(array2,ddof=1)\n",
        "    \n",
        "    #### The code below is for:\n",
        "    s_pooled = math.sqrt((((s1**2)*(n1-1))+((s2**2)*(n2-1)))/(n1+n2-2))\n",
        "    \n",
        "    #### The code below is for:\n",
        "    t_calc = (abs(x1-x2))*math.sqrt((n1*n2)/(n1+n2))/s_pooled\n",
        "    #### The code below is for:\n",
        "    return t_calc\n",
        "\n",
        "#### The code below is for:\n",
        "index_brass_light = np.argmin(brass_avg_by_year)+y1b\n",
        "index_brass_heavy = np.argmax(brass_avg_by_year)+y1b\n",
        "#### The code below is for:\n",
        "print(f\"Student T test for brass masses from years {index_brass_light} and {index_brass_heavy}, which differ the most:\")\n",
        "\n",
        "#### The code below is for:\n",
        "t_calc_brass = t_calc_pooled(brass_mass_by_year[index_brass_light],brass_mass_by_year[index_brass_heavy])\n",
        "#### The code below is for:\n",
        "dof_brass = len(brass_mass_by_year[index_brass_light]) + len(brass_mass_by_year[index_brass_heavy])-2\n",
        "#### The code below is for:\n",
        "t_crit_brass = abs(sp.special.stdtrit(dof_brass,0.025))\n",
        "#### The code below is for:\n",
        "print(f\"  Calculated t value = {t_calc_brass:.2f}; Critical t value at 95 percent confidence level = {t_crit_brass:.2f}\")\n",
        "\n",
        "#### The code below is for:\n",
        "brass_packaged_result = sp.stats.ttest_ind(brass_mass_by_year[index_brass_light],brass_mass_by_year[index_brass_heavy])\n",
        "print(f\"  SciPy TtestResult: Calculated t value = {abs(brass_packaged_result.statistic):.2f}; p-value = {brass_packaged_result.pvalue:.2e}\")\n",
        "\n",
        "#### The code below is for:\n",
        "index_zinc_light = np.argmin(zinc_avg_by_year)+y1z\n",
        "index_zinc_heavy = np.argmax(zinc_avg_by_year)+y1z\n",
        "#### The code below is for:\n",
        "print(f\"Student T test for zinc masses from years {index_zinc_light} and {index_zinc_heavy}, which differ the most:\")\n",
        "\n",
        "#### The code below is for:\n",
        "t_calc_zinc = t_calc_pooled(zinc_mass_by_year[index_zinc_light],zinc_mass_by_year[index_zinc_heavy])\n",
        "#### The code below is for:\n",
        "dof_zinc = len(zinc_mass_by_year[index_zinc_light]) + len(zinc_mass_by_year[index_zinc_heavy])-2\n",
        "#### The code below is for:\n",
        "t_crit_zinc = abs(sp.special.stdtrit(dof_zinc,0.025))\n",
        "#### The code below is for:\n",
        "print(f\"  Calculated t value = {t_calc_zinc:.2f}; Critical t value at 95 percent confidence level = {t_crit_zinc:.2f}\")\n",
        "\n",
        "#### The code below is for:\n",
        "zinc_packaged_result = sp.stats.ttest_ind(zinc_mass_by_year[index_zinc_light],zinc_mass_by_year[index_zinc_heavy])\n",
        "print(f\"  SciPy TtestResult: Calculated t value = {abs(zinc_packaged_result.statistic):.2f}; p-value = {zinc_packaged_result.pvalue:.2e}\")\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "7XUnIXLVIvZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6yqH32LSAAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5: Perform and apply a linear least-squares analysis with error propagation\n",
        "\n",
        "In the previous task, we ran a test to see if there is a significant difference between two data sets. Now, we ask whether there is a significant trend among many data sets. To accomplish this, we will plot the data and use linear regression with error propagation.  \n",
        "\n",
        "In linear regression, we fit the available data to a linear model.  The model has the equation of a line: $y = mx + b$, where $m$ is the slope and $b$ is the intercept.  With error propagation, the fit will also yield standard uncertainties $u_x$ and $u_b$ of the slope and intercept, respectively.\n",
        "\n",
        "In previous examples, you ran sample-code for both types of pennies (brass and zinc).  Here, the sample-code will be provided for brass pennies and you must modify it to generate your own code cell to analyze zinc pennies.\n",
        "\n",
        "5a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---2a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "5b)  Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.  \n",
        "\n",
        "5c)  Next, copy/paste the code into the s**econd code cell** below and **modify** the code to make a corresponding plot for the zinc pennies.  \n",
        "\n",
        "5d)  Take a look at the output for each type of penny and **decide as a group** if it looks reasonable. Ask for help if needed.\n",
        "\n",
        "5e)  Finally,  **answer the key question below** for each type of penny (brass and zinc) in your laboratory notebook.  Discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About the Data, Task 5**: Now that you have found the the best-fit line and its standard error, what does it mean?\n",
        "*   Q5a) State the *null hypothesis* in your own words.  Be specific.\n",
        "*   Q5b) State the conclusions you should draw if $m < u_m$, and if $m > u_m$.\n",
        "*   Q5c) Write one complete sentence to explain the meaning of $b$.\n",
        "*   Q5d) **As a group**, draw conclusions regarding both types of pennies from the output of Task 5.  Explain how these relate to the focus questions, and how you might modify your initial evaluations from Task 4.\n",
        "\n",
        "***Challenge Question***: (for a bonus point) The larger dataset plotted here was not altered by the Grubbs test, so you may notice outliers on your graph.  How could you plot the data set without outliers, using a Numpy array defined in Task 3?  Just write a short plan; you do not have to carry it out.\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#### The code below is for:\n",
        "plt.figure(figsize=(16,4))\n",
        "#### The code below is for:\n",
        "plt.axis()\n",
        "#### The code below is for:\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Mass in grams')\n",
        "#### The code below is for:\n",
        "plt.xticks(range(y1b,y2b+1))\n",
        "\n",
        "#### The code below is for:\n",
        "brass_array = np.transpose(big_db.to_numpy())\n",
        "#### The code below is for:\n",
        "brass_year_list = brass_array[1]\n",
        "brass_mass_list = brass_array[0]\n",
        "#### The code below is for:\n",
        "plt.plot(brass_year_list,brass_mass_list,'ob')\n",
        "\n",
        "#### The code below is for:\n",
        "model = sp.stats.linregress(brass_year_list,brass_mass_list)\n",
        "#### The code below is for:\n",
        "model_label = r'Linear model: ({:.2e}±{:.2e})∙x + ({:.2f}±{:.2f})'.format(model.slope,model.stderr,model.intercept,model.intercept_stderr)\n",
        "#### The code below is for:\n",
        "plt.plot(brass_year_list,model.slope*brass_year_list+model.intercept,'--b',label=model_label)\n",
        "\n",
        "#### The code below is for:\n",
        "plt.legend(loc=2)\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "k8s9gHwLVeHG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "260pct1dVh3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OXDp9dr0NlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6: Construct a histogram of stored data; construct a Gaussian model distribution; and compare the two\n",
        "\n",
        "All statistical testing is based on assumptions about the nature of the data.  One of these assumptions is that randomly distributed deviations from the mean should lead to a Gaussian distribution for a large data set.  This assumption can be tested by fitting the largest possible data set to a Gaussian model.  The position and shape of the model should match the mean and standard deviation of the data set.  The standard Gaussian distribution has an integrated size of 1 = 100\\%, which will need to be rescaled (*normalized*) to match the size of our data set.\n",
        "\n",
        "The Gaussian model we wish to calculate can easily be defined and normalized to the correct size using the Python math package:\n",
        "\n",
        "$y_{calc} = \\frac{Number\\ of\\ pennies}{100}\\cdot g(\\bar{x},s)$; where\n",
        "$g(\\bar{x},s) = \\frac{1}{s\\sqrt{2\\pi}}exp^{-(x-\\bar{x})^2/2s^2}$.\n",
        "\n",
        "In previous examples, you generated one graph at a time. Here, the sample-code will generate two graphs side-by-side.  The language (*syntax*) for doing so is a little different; it uses \"object-oriented\" commands to set up the graphs.  See if you can tell how the code specifies that two data sets (the histogram and the model curve) should be placed *together* on the same graph, and that the data for brass and zinc pennies should be placed on *different* graphs in the figure.\n",
        "\n",
        "To test whether the data set deviates significantly from an appropriately fitted Gaussian model, the $\\chi^2$ (*chi-squared*) statistic is used.  It can easily be calculated using Numpy arrays and the Python math package:\n",
        "\n",
        "$\\chi^2_{calc} = \\Sigma_n \\frac{(y_{obs}-y_{calc})^2}{y_{calc}}$\n",
        "\n",
        "For comparison, critical values of chi-squared can be found in your lab manual or looked up using SciPy at a given level of confidence (usually 95%).  If the calculated $\\chi^2$ value is larger than the critical value, then the difference is significant at that level of confidence.  \n",
        "\n",
        "6a) Using the information above, double-click here in this **text cell** and type into each of the comment lines to **explain the purpose** of each line of sample-code below in this text cell (they should look like the example shown here).\n",
        "\n",
        "---\n",
        "```\n",
        "#### The code below is for:\n",
        "```\n",
        "---\n",
        "\n",
        "6b) Copy/paste all the code along with your explanations into the **code cell** just below this text cell, and run it.\n",
        "\n",
        "6c) Take a look at the output for each type of penny and **decide as a group** if it looks reasonable. Ask for help if needed.\n",
        "\n",
        "6d) Finally, **answer the key question** below for each type of penny (brass and zinc) in your laboratory notebook. Discuss as a group.  Ask for help if needed.\n",
        "\n",
        "#### **Thinking About the Data, Task 6**: Now that you have created the histograms and fit them to a Gaussian model, what does it mean?\n",
        "*   Q6a) State the null hypothesis (for each type of penny) in your own words. Be specific.\n",
        "*   Q6b) State the conclusions you should draw if $\\chi^2_{calc} < \\chi^2_{critical}$, and if $\\chi^2_{calc} > \\chi^2_{critical}$.\n",
        "*   Q6c) **As a group**, draw conclusions regarding both types of pennies from the output of Task 6. Explain how these relate to the validity of tests performed in Tasks 4 and 5, and how you might modify your initial evaluations from Tasks 4 and 5.\n",
        "\n",
        "\n",
        "***Challenge Question***: (for a bonus point) The larger dataset plotted here was not altered by the Grubbs test, so you may notice outliers on your histogram. How could these affect the calculated value of $\\chi^2$? Based on what you have seen in your results, do you think removing the outliers could change your assessment of the validity of tests performed in Tasks 4 and 5?\n",
        "\n",
        "---\n",
        "```python\n",
        "#### The code below is for:\n",
        "def gaussian(x, avg, sd):\n",
        "    return (\n",
        "        1.0 / (np.sqrt(2*np.pi)*sd) * np.exp(-np.power((x - avg)/sd,2)/2)\n",
        "    )\n",
        "\n",
        "#### The code below is for:\n",
        "def chi_squared_statistic(y_array,model_array):\n",
        "    n = len(x_array)  \n",
        "    chi_sq = 0\n",
        "    for ibin in range(n):     \n",
        "        ycalc = model_array[ibin]\n",
        "        yobs = y_array[ibin]\n",
        "        if yobs > 1: chi_sq = chi_sq + ((yobs-ycalc)**2)/ycalc\n",
        "    return chi_sq  \n",
        "\n",
        "#### The code below is for:\n",
        "dual_figure = plt.figure(figsize=(14,6))\n",
        "plt_brass, plt_zinc = dual_figure.subplots(1,2)\n",
        "\n",
        "#### The code below is for:\n",
        "n_bins_brass = math.ceil((np.max(brass_array[0])-np.min(brass_array[0]))/0.01)\n",
        "#### The code below is for:\n",
        "bin_midpoints_brass = (np.arange(n_bins_brass)*0.01+np.min(brass_array[0])+0.005)\n",
        "#### The code below is for:\n",
        "bin_endpoints_brass = (np.arange(n_bins_brass+1)*0.01+np.min(brass_array[0]))\n",
        "#### The code below is for:\n",
        "brass_hist_np = np.histogram(brass_mass_list,bins=bin_endpoints_brass)\n",
        "brass_hist_values = brass_hist_np[0]\n",
        "#### The code below is for:\n",
        "plt_brass.stairs(brass_hist_values,bin_endpoints_brass,fill=True)\n",
        "\n",
        "#### The code below is for:\n",
        "avg_brass = np.average(brass_mass_list)\n",
        "#### The code below is for:\n",
        "sd_brass = np.std(brass_mass_list,ddof=1)\n",
        "#### The code below is for:\n",
        "n_brass = len(brass_mass_list)\n",
        "#### The code below is for:\n",
        "brass_model = ((n_brass/100))*gaussian(bin_midpoints_brass,avg_brass,sd_brass)\n",
        "#### The code below is for:\n",
        "chi_squared_brass = chi_squared_statistic(brass_hist_values,brass_model)\n",
        "#### The code below is for:\n",
        "chi_squared_crit_brass = sp.stats.chi2.ppf(0.95,n_bins_brass-1)\n",
        "#### The code below is for:\n",
        "brass_model_label = r'Model Chi-squared = {:.2f}, Critical value = {:.2f}'.format(chi_squared_brass,chi_squared_crit_brass)\n",
        "#### The code below is for:\n",
        "plt_brass.plot(bin_midpoints_brass,brass_model,'--b',label=brass_model_label)\n",
        "\n",
        "#### The code below is for:\n",
        "plt_brass.set_xlabel('Masses of Brass Pennies')\n",
        "plt_brass.set_ylabel('Number of Brass Pennies')\n",
        "#### The code below is for:\n",
        "plt_brass.set_title('Brass Mass Distribution and Gaussian Model')\n",
        "#### The code below is for:\n",
        "plt_brass.legend(loc=9)\n",
        "\n",
        "#### The code below is for:\n",
        "n_bins_zinc = math.ceil((np.max(zinc_array[0])-np.min(zinc_array[0]))/0.01)\n",
        "#### The code below is for:\n",
        "bin_midpoints_zinc = (np.arange(n_bins_zinc)*0.01+np.min(zinc_array[0])+0.005)\n",
        "#### The code below is for:\n",
        "bin_endpoints_zinc = (np.arange(n_bins_zinc+1)*0.01+np.min(zinc_array[0]))\n",
        "#### The code below is for:\n",
        "zinc_hist_np = np.histogram(zinc_mass_list,bins=bin_endpoints_zinc)\n",
        "zinc_hist_values = zinc_hist_np[0]\n",
        "#### The code below is for:\n",
        "plt_zinc.stairs(zinc_hist_values,bin_endpoints_zinc,fill=True)\n",
        "\n",
        "#### The code below is for:\n",
        "avg_zinc = np.average(zinc_mass_list)\n",
        "#### The code below is for:\n",
        "sd_zinc = np.std(zinc_mass_list,ddof=1)\n",
        "#### The code below is for:\n",
        "n_zinc = len(zinc_mass_list)\n",
        "#### The code below is for:\n",
        "zinc_model = ((n_zinc/100))*gaussian(bin_midpoints_zinc,avg_zinc,sd_zinc)\n",
        "#### The code below is for:\n",
        "chi_squared_zinc = chi_squared_statistic(zinc_hist_values,zinc_model)\n",
        "#### The code below is for:\n",
        "chi_squared_crit_zinc = sp.stats.chi2.ppf(0.95,n_bins_zinc-1)\n",
        "#### The code below is for:\n",
        "zinc_model_label = r'Model Chi-squared = {:.2f}, Critical value = {:.2f}'.format(chi_squared_zinc,chi_squared_crit_zinc)\n",
        "#### The code below is for:\n",
        "plt_zinc.plot(bin_midpoints_zinc,zinc_model,'--b',label=zinc_model_label)\n",
        "\n",
        "#### The code below is for:\n",
        "plt_zinc.set_xlabel('Masses of Zinc Pennies')\n",
        "plt_zinc.set_ylabel('Number of Zinc Pennies')\n",
        "#### The code below is for:\n",
        "plt_zinc.set_title('Zinc Mass Distribution and Gaussian Model')\n",
        "#### The code below is for:\n",
        "plt_zinc.legend(loc=9)\n",
        "\n",
        "#### The code below is for:\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "NcCq4uKn0lmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Congratulations, you did it!***\n",
        "\n",
        "Please download your copy of this notebook to turn in.\n",
        "\n",
        "Remember to write a summary in your laboratory notebook, by hand, and to turn in copies of your notebook pages."
      ],
      "metadata": {
        "id": "9kRNI-uK3Xan"
      }
    }
  ]
}